{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "48d33628e09b469eb8bdc255e637458b",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Homework 2 (HW2)\n",
    "By the end of this homework, we expect you to be able to:\n",
    "\n",
    "- Preprocess data and make it amenable to statistical analysis and machine learning models;\n",
    "- Train and test out-of-the-box machine learning models in Python;\n",
    "- Carry out simple multivariate regression analyses;\n",
    "- Use techniques to control for covariates;\n",
    "- Conduct an observational study and reason about its results.\n",
    "\n",
    "---\n",
    "\n",
    "- Homework release: Fri 17 Nov 2023\t\n",
    "\n",
    "- **Homework Due**: Fri 01 Dec 2023, 23:59\t\n",
    "\n",
    "- Grades released: Mon 11 Dec 2023\t\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Some rules\n",
    "1. You are allowed to use any built-in Python library that comes with Anaconda. If you want to use an external library, you may do so, but must justify your choice.\n",
    "\n",
    "2. Make sure you use the `data` folder provided in the repository in read-only mode. (Or alternatively, be sure you don’t change any of the files.)\n",
    "\n",
    "3. Be sure to provide a concise textual description of your thought process, the assumptions you made, the solution you implemented, and explanations for your answers. A notebook that only has code cells will not suffice.\n",
    "\n",
    "4. For questions containing the **/Discuss:/** prefix, answer not with code, but with a textual explanation **(in markdown)**.\n",
    "\n",
    "5. Back up any hypotheses and claims with data, since this is an important aspect of the course.\n",
    "\n",
    "6. Please write all your comments in **English**, and use meaningful variable names in your code. Your repo should have a single notebook (plus the required data files) in the master/main branch. **If there are multiple notebooks present, we will not grade anything.**\n",
    "\n",
    "7. We will **not run your notebook for you!** Rather, we will grade it as is, which means that only the results contained in your evaluated code cells will be considered, and we will not see the results in unevaluated code cells. Thus, be sure to hand in a **fully-run and evaluated notebook**. In order to check whether everything looks as intended, you can check the rendered notebook on the GitHub website once you have pushed your solution there.\n",
    "\n",
    "8. In continuation to the previous point, interactive plots, such as those generated using the `plotly` package, should be strictly avoided!\n",
    "\n",
    "9. Make sure to print results and/or dataframes that confirm you have properly addressed the task.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-17T17:54:27.233757Z",
     "start_time": "2023-11-17T17:54:26.757026Z"
    },
    "cell_id": "625617a477d24ad79bec3365a3da1fc3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2106,
    "execution_start": 1701441886677,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# regression / matching\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "\n",
    "# machine lerning\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# statistical analysis\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "fcd2c9ce20bd44848c74d0d4c4b79edf",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Context\n",
    "\n",
    "After two years, the EPFL Baseball Club is broke. The new Dean transferred all funds to EPFL's new poster child: its super-competitive Pétanque club. After struggling so much to learn about baseball, you have unfortunately been laid off...\n",
    "\n",
    "*(...) 1 month after, you manage to get another job (!) (...)*\n",
    "\n",
    "Congratulations! You have just been hired as a data scientist at the Association for Computational Linguistics (ACL), a professional organization for people working on natural language processing. The ACL organizes several of the top conferences and workshops in the field of computational linguistics and natural language processing.\n",
    "Your boss, Dr. Tiancheng, knows of your expertise in observational studies and asks you to investigate a question that’s been bothering everyone who has ever submitted a paper to a conference: should I spend time on writing rebuttals?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Rebuttals, conferences, and getting your papers accepted\n",
    "\n",
    "Rebuttals in ACL (Association for Computational Linguistics) conferences and in many other academic conferences are an important part of the peer-review process. They allow authors of submitted papers to respond to the reviews and comments provided by the reviewers before a final decision is made regarding the acceptance of the paper. Here's how the rebuttal process typically works in ACL conferences:\n",
    "\n",
    "- Paper Submission: Authors submit their research papers to the ACL conference for review. These papers present novel research findings in computational linguistics, natural language processing, and related areas.\n",
    "- Peer Review: The papers undergo a peer-review process after the initial submission. The program committee or reviewers are experts in the field who evaluate the papers based on their quality, significance, novelty, methodology, and other relevant criteria. They provide comments and scores for each paper.\n",
    "- Rebuttal Period: After receiving the reviews, authors are given a specific period (usually around a week) to write a rebuttal. The rebuttal is a formal response to the reviewers' comments. It allows authors to clarify misunderstandings, address concerns, and provide additional information to support their paper's quality. \n",
    "- Final Review: After receiving the rebuttals, the reviewers may reconsider their initial assessments in light of the authors' responses. Reviewers may choose to maintain or adjust their reviews and scores based on the quality and effectiveness of the author's rebuttal.\n",
    "- Final Decision: The program committee or conference organizers consider the initial reviews/scores, rebuttals, and revised reviews/scores to make a final decision on the acceptance of the papers. The decision can be acceptance, rejection, or conditional acceptance with a request for revisions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Data\n",
    "\n",
    "- `tmp_id`: Unique identifier for each paper in the format \"P{number}\".\n",
    "- `status`: Accept or Reject.\n",
    "- `submission_type`: Short vs. Long (papers can have different lengths). We do not use this column in this homework. \n",
    "- `track`: Track to which the paper was submitted, broadly speaking, the \"topic\" of the paper.\n",
    "- `scores_before`: Scores received before rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework. \n",
    "- `scores_after`: Scores received after rebuttal. This is a nested JSON with many fields, but we will use only the \"overall\" score for the homework.\n",
    "- `had_rebuttal`: True or False.\n",
    "\n",
    "\n",
    "Note that: \n",
    " - reviews are assigned numbers, e.g., \"2\";\n",
    " - papers can have different numbers of reviews;\n",
    " - review numbers are arbitrary, e.g., `P1` in the dataframe has two reviews numbered \"2\" and \"3\" (but no review \"1\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f84549a500a348e98c6fdadf70adca0d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Task 1 (10 pts): Get to Know Your Data\n",
    "\n",
    "As a good data scientist, you first load the data and perform some small sanity checks on it.\n",
    "\n",
    "- You are expected to continuously alter your dataframe as you complete the tasks. E.g., if you are asked to filter the data in a specific task, continue using the filtered dataset in the subsequent tasks.\n",
    "- When we tell you to \"print the dataframe,\" make sure you print it in a way that shows the total number of rows and columns in it (`display(df)` should suffice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0474fa5e723848609254a59930495515",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**1.1** Load the dataset containing ACL reviews into memory using pandas. \n",
    "- For each paper, create rows `overall_score_before_avg` and `overall_score_after_avg` containing the average (overall) scores before and after rebuttal.\n",
    "- For each paper, create rows `overall_score_before_std` and `overall_score_after_std` containing the standard deviation of the overall scores before and after the rebuttal.\n",
    "- Print the four newly created rows for paper `P17`.\n",
    "- Print the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "1ef5ec462d76403ab568f6d571e8e6cd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 403,
    "execution_start": 1701441888781,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P17</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tmp_id  overall_score_before_avg  overall_score_before_std  \\\n",
       "16    P17                       4.5                       0.5   \n",
       "\n",
       "    overall_score_after_avg  overall_score_after_std  \n",
       "16                      4.5                      0.5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Question Answering</td>\n",
       "      <td>True</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P3</td>\n",
       "      <td>Accept</td>\n",
       "      <td>Short</td>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>True</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.247219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P5</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>P1541</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>True</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>P1542</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>P1543</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.942809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>P1544</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>False</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>P1545</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tmp_id  status submission_type  \\\n",
       "0        P1  Reject            Long   \n",
       "1        P2  Reject            Long   \n",
       "2        P3  Accept           Short   \n",
       "3        P4  Reject           Short   \n",
       "4        P5  Reject            Long   \n",
       "...     ...     ...             ...   \n",
       "1540  P1541  Reject           Short   \n",
       "1541  P1542  Reject            Long   \n",
       "1542  P1543  Reject            Long   \n",
       "1543  P1544  Reject           Short   \n",
       "1544  P1545  Reject           Short   \n",
       "\n",
       "                                               track  had_rebuttal  \\\n",
       "0                                   Machine Learning          True   \n",
       "1                                 Question Answering          True   \n",
       "2               Multidisciplinary and Area Chair COI          True   \n",
       "3                                   Machine Learning          True   \n",
       "4                                  Document Analysis          True   \n",
       "...                                              ...           ...   \n",
       "1540  Textual Inference and Other Areas of Semantics          True   \n",
       "1541                                Machine Learning         False   \n",
       "1542                                Machine Learning          True   \n",
       "1543                                    Social Media         False   \n",
       "1544          Information Extraction and Text Mining          True   \n",
       "\n",
       "      overall_score_before_avg  overall_score_before_std  \\\n",
       "0                     2.500000                  0.500000   \n",
       "1                     3.333333                  0.942809   \n",
       "2                     4.666667                  0.471405   \n",
       "3                     3.000000                  0.816497   \n",
       "4                     3.000000                  0.000000   \n",
       "...                        ...                       ...   \n",
       "1540                  2.333333                  0.471405   \n",
       "1541                  2.000000                  0.816497   \n",
       "1542                  2.666667                  0.942809   \n",
       "1543                  2.000000                  0.000000   \n",
       "1544                  3.000000                  0.816497   \n",
       "\n",
       "      overall_score_after_avg  overall_score_after_std  \n",
       "0                    2.500000                 0.500000  \n",
       "1                    3.333333                 0.942809  \n",
       "2                    4.666667                 0.471405  \n",
       "3                    2.666667                 1.247219  \n",
       "4                    2.500000                 0.500000  \n",
       "...                       ...                      ...  \n",
       "1540                 2.333333                 0.471405  \n",
       "1541                 2.000000                 0.816497  \n",
       "1542                 2.666667                 0.942809  \n",
       "1543                 2.000000                 0.000000  \n",
       "1544                 3.000000                 0.816497  \n",
       "\n",
       "[1538 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def stat_overall_scores(scores_df,function=np.mean):\n",
    "    \"\"\"\n",
    "    Function that takes the list of overall scores of each paper and return a \n",
    "    list containing the result of the specified function (mean or std)\n",
    "    \n",
    "    Arguments :\n",
    "                @scores_df <DataFrame> : for each paper, contains its peer review scores\n",
    "                @function <str> : 'np.mean' or 'np.std'\n",
    "                \n",
    "    Return :\n",
    "                @overall_scores <list> : mean or std of the overall scores given by peers\n",
    "    \"\"\"\n",
    "    \n",
    "    overall_scores = [function([paper[peer]['scores']['overall_score']#peer overall scores\n",
    "                                for peer in paper])\n",
    "                      for paper in scores_df]\n",
    "    return overall_scores\n",
    "\n",
    "# Loading of the dataset\n",
    "PATH = \"./data/acl18_v1_numerical_final.json\"\n",
    "ACL_df = pd.read_json(PATH)\n",
    "\n",
    "#Creation of new columns\n",
    "ACL_df = ACL_df.assign(overall_score_before_avg = \n",
    "                       stat_overall_scores(ACL_df.scores_before)).copy(deep=True)\n",
    "ACL_df = ACL_df.assign(overall_score_before_std = \n",
    "                       stat_overall_scores(ACL_df.scores_before,np.std)).copy(deep=True)\n",
    "ACL_df = ACL_df.assign(overall_score_after_avg = \n",
    "                       stat_overall_scores(ACL_df.scores_after)).copy(deep=True)\n",
    "ACL_df = ACL_df.assign(overall_score_after_std = \n",
    "                       stat_overall_scores(ACL_df.scores_after,np.std)).copy(deep=True)\n",
    "\n",
    "#Deletion of the useless columns\n",
    "ACL_df = ACL_df.drop(columns=['scores_before','scores_after'])\n",
    "\n",
    "#Display results\n",
    "display(ACL_df[ACL_df.tmp_id==\"P17\"][['tmp_id',\n",
    "                                      'overall_score_before_avg',\n",
    "                                      'overall_score_before_std',\n",
    "                                      'overall_score_after_avg',\n",
    "                                      'overall_score_after_std']])\n",
    "display(ACL_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0531b03288e641c79fc225164527b159",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**1.2** Create a single plot with 14 inches of width and 4 inches of height. The plot should contain two panels: \n",
    "- **Panel A**: The distribution of `overall_score_before_avg` for papers that were accepted and papers that were rejected.\n",
    "- **Panel B**: The distribution of `overall_score_before_avg` for papers that had rebuttals vs. papers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_id": "374de175a09745f1b9f4801fcde74a7a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 580,
    "execution_start": 1701441889193,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1008x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = stats.norm.ppf(0.975) # z-score for 95% confidence intervals (1.96)\n",
    "accept_df = ACL_df[ACL_df.status == 'Accept']\n",
    "reject_df = ACL_df[ACL_df.status == 'Reject']\n",
    "with_rebuttals_df = ACL_df[ACL_df.had_rebuttal]\n",
    "without_rebuttals_df = ACL_df[ACL_df.had_rebuttal==False]\n",
    "\n",
    "Nbin = 12\n",
    "fig, (A,B) = plt.subplots(1, 2, figsize=(14,4))\n",
    "\n",
    "#Distribution of accepted and rejected papers depending on their mean overall score\n",
    "A.hist(reject_df.overall_score_before_avg,color='r',alpha=.7,bins=Nbin)\n",
    "A.hist(accept_df.overall_score_before_avg,color='g',alpha=.7,bins=Nbin)\n",
    "A.legend(['Rejected papers','Accepted papers'])\n",
    "A.grid(axis='y')\n",
    "A.set_xlabel('Overall Score Before')\n",
    "A.set_ylabel('Number of papers')\n",
    "A.set_title(\"Distribution of overall score before eventual rebuttals\")\n",
    "\n",
    "#Distribution of papers with or without rebuttals depending on their mean overall score\n",
    "B.hist(with_rebuttals_df.overall_score_before_avg,color='g',alpha=.7,bins=Nbin)\n",
    "B.hist(without_rebuttals_df.overall_score_before_avg,color='r',alpha=.7,bins=Nbin)\n",
    "B.legend(['With rebuttal','Without rebuttal'])\n",
    "B.grid(axis='y')\n",
    "B.set_xlabel('Overall Score Before')\n",
    "B.set_ylabel('Number of papers')\n",
    "B.set_title(\"Distribution of overall score before eventual rebuttals\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice two things :\n",
    "- Accepted paper have mainly high overall scores before eventual rebuttals. \n",
    "- Paper without rebuttals seems to have lower overall scores before eventual rebuttals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f41b64135a474f89887b038c6b40bc60",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**1.3** **/Discuss/:** If you know a paper had a rebuttal, is it more or less likely that it was accepted? Does this mean that rebuttals help papers get accepted? Explain why or why not, providing a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** By looking at our histograms : a paper that has a rebuttal is more likely to have a high overall score before, and a paper that has a high overall score before is more likely to be accepted. **Hence it seems more likely to be accepted when you do rebuttals.**\n",
    "\n",
    "Looking a little bit deeper, we provide the following statistics :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_id": "a545fab210ef48e79817795687716899",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 23,
    "execution_start": 1701441889776,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 350 paper with rebuttals that were accepted.\n",
      "There are 1192 paper with rebuttals.\n",
      "There are 29 paper without rebuttals that were accepted.\n",
      "There are 346 paper without rebuttals.\n"
     ]
    }
   ],
   "source": [
    "# Recuperation of statistics\n",
    "numerator = ACL_df.query('status==\"Accept\" and had_rebuttal==True').shape[0]\n",
    "denominator = ACL_df.query('had_rebuttal==True').shape[0]\n",
    "numerator2 = ACL_df.query('status==\"Accept\" and had_rebuttal==False').shape[0]\n",
    "denominator2 = ACL_df.query('had_rebuttal==False').shape[0]\n",
    "print(f\"There are {numerator} paper with rebuttals that were accepted.\")\n",
    "print(f\"There are {denominator} paper with rebuttals.\")\n",
    "print(f\"There are {numerator2} paper without rebuttals that were accepted.\")\n",
    "print(f\"There are {denominator2} paper without rebuttals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "318338ce27e742708334e7a40af863ab",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "|                  | Accepted  | Rejected |\n",
    "|------------------|-----------|----------|\n",
    "| With rebuttal    |   350     |  842     |\n",
    "| Without rebuttal |   29      |  317     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "92f38893cd264f1aa16f15630b8195a0",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "If $A$ is the event : \"The paper is accepted\" and $R$ : \"The paper had a rebuttal\". Let's compute the following values :\n",
    "\n",
    "$$P(A|R)=\\frac{P(A\\cap R)}{P(R)}=\\frac{350}{1192}\\approx 0.294$$\n",
    "\n",
    "Naïvely, we might conclude that having a rebuttal leads to a probability of being accepted inferior to 0.5. Hence, having a rebuttal does not imply that the paper will be accepted. \n",
    "\n",
    "However, when comparing this result to the probability of being accepted:\n",
    "\n",
    "$$P\\left(A\\right)=\\frac{350+29}{842+317+350+29}\\approx 0.246$$\n",
    "\n",
    "We understand that being accepted is a rare event, and having a rebuttal actually increases your chances to be accepted. \n",
    "\n",
    "In fact, not to do a rebuttal even makes chances to be accepted a lot smaller:\n",
    "$$P\\left(A|\\overline{R}\\right)=\\frac{P\\left(A\\cap \\overline{R}\\right)}{P\\left(\\overline{R}\\right)}=\\frac{29}{346}\\approx 0.0838$$\n",
    "\n",
    "Only considering these elements, **we might conclude that rebuttals seems to help being accepted**. This could be because if you have a low score before, you might have not been understood by your peers, so doing a rebuttal can clarify you paper and increase your score after, what leads your paper to be accepted.\n",
    "\n",
    "This would however be more careful to do a deeper anlysis to check if some confounders could not threaten our findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "cd535a182b604d6cac63589c45ee3f16",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**1.4** Print the percentage of rebuttals per track in the conference (defined by the `track` column). \n",
    "\n",
    "**/Discuss:/** Using \"the logic\" of hypothesis testing (see slide 29 of Lecture 4), how would you devise a statistical test to refute the following null hypothesis: all tracks have the same fraction of papers with rebuttals. Your statistical test should consider all categories at once, rather than comparing the fraction of rebuttals between pairs of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_id": "aba119f522be4a5abebc41c3eebe6002",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 740,
    "execution_start": 1701441889789,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track</th>\n",
       "      <th>percentage_with_rebuttal</th>\n",
       "      <th>confidence_interval_95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dialogue and Interactive Systems</td>\n",
       "      <td>77.528090</td>\n",
       "      <td>8.671668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Discourse and Pragmatics</td>\n",
       "      <td>80.434783</td>\n",
       "      <td>11.463928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Document Analysis</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>8.701445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Generation</td>\n",
       "      <td>77.966102</td>\n",
       "      <td>10.575981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information Extraction and Text Mining</td>\n",
       "      <td>76.836158</td>\n",
       "      <td>6.215121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linguistic Theories Cognitive Modeling and Psy...</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>17.323798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>80.869565</td>\n",
       "      <td>7.188763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Machine Translation</td>\n",
       "      <td>82.075472</td>\n",
       "      <td>7.301729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multidisciplinary and Area Chair COI</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>10.557155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multilinguality</td>\n",
       "      <td>80.645161</td>\n",
       "      <td>13.907568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phonology Morphology and Word Segmentation</td>\n",
       "      <td>85.185185</td>\n",
       "      <td>13.399740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Question Answering</td>\n",
       "      <td>72.839506</td>\n",
       "      <td>9.686300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Resources and Evaluation</td>\n",
       "      <td>73.239437</td>\n",
       "      <td>10.297672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence-level semantics</td>\n",
       "      <td>78.888889</td>\n",
       "      <td>8.431218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentiment Analysis and Argument Mining</td>\n",
       "      <td>78.823529</td>\n",
       "      <td>8.685471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Social Media</td>\n",
       "      <td>73.770492</td>\n",
       "      <td>11.038742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Summarization</td>\n",
       "      <td>74.509804</td>\n",
       "      <td>11.960692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tagging Chunking Syntax and Parsing</td>\n",
       "      <td>77.049180</td>\n",
       "      <td>10.552765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Textual Inference and Other Areas of Semantics</td>\n",
       "      <td>77.192982</td>\n",
       "      <td>10.892657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vision Robotics Multimodal Grounding and Speech</td>\n",
       "      <td>81.132075</td>\n",
       "      <td>10.533398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Word-level Semantics</td>\n",
       "      <td>86.075949</td>\n",
       "      <td>7.634107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                track  \\\n",
       "0                    Dialogue and Interactive Systems   \n",
       "1                            Discourse and Pragmatics   \n",
       "2                                   Document Analysis   \n",
       "3                                          Generation   \n",
       "4              Information Extraction and Text Mining   \n",
       "5   Linguistic Theories Cognitive Modeling and Psy...   \n",
       "6                                    Machine Learning   \n",
       "7                                 Machine Translation   \n",
       "8                Multidisciplinary and Area Chair COI   \n",
       "9                                     Multilinguality   \n",
       "10         Phonology Morphology and Word Segmentation   \n",
       "11                                 Question Answering   \n",
       "12                           Resources and Evaluation   \n",
       "13                           Sentence-level semantics   \n",
       "14             Sentiment Analysis and Argument Mining   \n",
       "15                                       Social Media   \n",
       "16                                      Summarization   \n",
       "17                Tagging Chunking Syntax and Parsing   \n",
       "18     Textual Inference and Other Areas of Semantics   \n",
       "19    Vision Robotics Multimodal Grounding and Speech   \n",
       "20                               Word-level Semantics   \n",
       "\n",
       "    percentage_with_rebuttal  confidence_interval_95  \n",
       "0                  77.528090                8.671668  \n",
       "1                  80.434783               11.463928  \n",
       "2                  73.000000                8.701445  \n",
       "3                  77.966102               10.575981  \n",
       "4                  76.836158                6.215121  \n",
       "5                  75.000000               17.323798  \n",
       "6                  80.869565                7.188763  \n",
       "7                  82.075472                7.301729  \n",
       "8                  68.000000               10.557155  \n",
       "9                  80.645161               13.907568  \n",
       "10                 85.185185               13.399740  \n",
       "11                 72.839506                9.686300  \n",
       "12                 73.239437               10.297672  \n",
       "13                 78.888889                8.431218  \n",
       "14                 78.823529                8.685471  \n",
       "15                 73.770492               11.038742  \n",
       "16                 74.509804               11.960692  \n",
       "17                 77.049180               10.552765  \n",
       "18                 77.192982               10.892657  \n",
       "19                 81.132075               10.533398  \n",
       "20                 86.075949                7.634107  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_df = ACL_df[['track','had_rebuttal']].groupby('track').had_rebuttal\n",
    "\n",
    "# Percentage of paper with rebuttals among tracks\n",
    "stat_dict = {\"track\":[], \"percentage_with_rebuttal\":[], \"confidence_interval_95\":[]}\n",
    "for track in track_df:\n",
    "    stat_dict[\"track\"].append(track[0])\n",
    "    stat_dict[\"percentage_with_rebuttal\"].append(track[1].mean()*100)\n",
    "    stat_dict[\"confidence_interval_95\"].append(z*track[1].sem(ddof=0)*100)\n",
    "df_stat = pd.DataFrame(stat_dict)\n",
    "display( df_stat )\n",
    "df_stat['percentage_without_rebuttal'] = 100-df_stat['percentage_with_rebuttal']\n",
    "\n",
    "# Corresponding plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax = df_stat.plot(x='track', y=['percentage_with_rebuttal','percentage_without_rebuttal'],\n",
    "                  kind='barh', stacked=True, color=['green', 'red'], alpha=0.7)\n",
    "ax.invert_yaxis()\n",
    "for i, value in enumerate(df_stat[\"percentage_with_rebuttal\"]):\n",
    "    # add the confidence interval at 95% to each track\n",
    "    plt.errorbar(value, i, xerr=df_stat[\"confidence_interval_95\"].iloc[i],\n",
    "                 linestyle='', color='black', capsize=2)\n",
    "plt.title('Percentage of rebuttals per track in the conference')\n",
    "plt.xlabel('Ratio')\n",
    "plt.xlim((0, 100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "24562278f3b74e9bafe8afc732f31871",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 6,
      "type": "marks"
     },
     {
      "fromCodePoint": 305,
      "marks": {
       "bold": true
      },
      "toCodePoint": 307,
      "type": "marks"
     },
     {
      "fromCodePoint": 314,
      "marks": {
       "bold": true
      },
      "toCodePoint": 315,
      "type": "marks"
     },
     {
      "fromCodePoint": 317,
      "marks": {
       "bold": true
      },
      "toCodePoint": 319,
      "type": "marks"
     }
    ]
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "**Theoretically,** to design a statistical test to refute that all tracks have the same fraction of papers with rebuttals, we consider the latter to be true. This means that if we had access to a large amount of papers for each track, we should have the same fraction of papers with rebuttals for each of them. But here we just have a small sample, and this fraction can fluctuate from the one of the absolute distribution.\n",
    "\n",
    "This is why we would use a number $t$, characterizing the difference between each empirical percentage and the theoretical one, and taking into account the size of each sample (a given bias found for a track with many papers should be more penlized than for a track with few papers). For intance, $t$ could be a weighted sum of the squared differences between theroetical and empirical percentages.\n",
    "\n",
    "The most important would be then to find the probability that a difference equal or higher than $t$ had be found by luck. If this probability is high, this means it is possible that all our percentages comes from the same initial distribution. But if it is found to be really low, then the difference $t$ (that is supposed to be non-zero) is not due to chance, and this means our initial hypothesis that every track has the same fraction of papers with rebuttal is false.\n",
    "\n",
    "**In practice,**  an adapted test for this is the ANalysis Of VAriance (ANOVA test). It will compute a F-test to characterize whether the differences in percentages areseen in the previous graph are due to chance. We will obtain a p-value which allows us to reject the  null hypothesis (\"all tracks have the same fraction of papers with rebuttals\") if and only if below 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e5a2b7b44e54a47910405d6630bf694",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Task 2 (10pts): Prediction\n",
    "\n",
    "You decide to investigate further the effect of rebuttals on acceptance using your machine learning skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "71dee5e27fd249d884a95928ed4ce5de",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.1** For each possible value in the `track` column, create a new column called {track}-onehot (e.g., for track=Generation, create Generation-onehot). Collectively, these new columns should \"one hot-encode\" the track column---for instance, if for a given paper the `track` column is filled with the value \"Generation\", the Generation-onehot column should equal 1 and all other {track}-onehot columns should equal 0. \n",
    "\n",
    "Print the column names of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "cell_id": "2a51fb43eee5492fac8cfcd5290ce6d8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1077,
    "execution_start": 1701441890531,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue and Interactive Systems-onehot\n",
      "- Discourse and Pragmatics-onehot\n",
      "- Document Analysis-onehot\n",
      "- Generation-onehot\n",
      "- Information Extraction and Text Mining-onehot\n",
      "- Linguistic Theories Cognitive Modeling and Psycholinguistics-onehot\n",
      "- Machine Learning-onehot\n",
      "- Machine Translation-onehot\n",
      "- Multidisciplinary and Area Chair COI-onehot\n",
      "- Multilinguality-onehot\n",
      "- Phonology Morphology and Word Segmentation-onehot\n",
      "- Question Answering-onehot\n",
      "- Resources and Evaluation-onehot\n",
      "- Sentence-level semantics-onehot\n",
      "- Sentiment Analysis and Argument Mining-onehot\n",
      "- Social Media-onehot\n",
      "- Summarization-onehot\n",
      "- Tagging Chunking Syntax and Parsing-onehot\n",
      "- Textual Inference and Other Areas of Semantics-onehot\n",
      "- Vision Robotics Multimodal Grounding and Speech-onehot\n",
      "- Word-level Semantics-onehot\n",
      "- had_rebuttal\n",
      "- overall_score_after_avg\n",
      "- overall_score_after_std\n",
      "- overall_score_before_avg\n",
      "- overall_score_before_std\n",
      "- status\n",
      "- submission_type\n",
      "- tmp_id\n",
      "- track\n"
     ]
    }
   ],
   "source": [
    "for track_name in ACL_df.track:\n",
    "    new_column=track_name+\"-onehot\"\n",
    "    ACL_df[new_column]=ACL_df.track.apply(lambda x: int(x==track_name))\n",
    "\n",
    "for column in sorted(ACL_df.columns):\n",
    "    print(\"- \"+column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "da1a7b277f54480cb72363351e377946",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.2** Create a column `had_rebuttal_int`, which equals 1 if the paper had a rebuttal, and 0 otherwise, and a column `accepted_int`, which equals 1 if the paper was accepted, and 0 otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "cell_id": "748ad291e7a94676a70cc9b163728f2e",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 30,
    "execution_start": 1701441891611,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>had_rebuttal_int</th>\n",
       "      <th>status</th>\n",
       "      <th>accepted_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Accept</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1543</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      had_rebuttal  had_rebuttal_int  status  accepted_int\n",
       "0             True                 1  Reject             0\n",
       "1             True                 1  Reject             0\n",
       "2             True                 1  Accept             1\n",
       "3             True                 1  Reject             0\n",
       "4             True                 1  Reject             0\n",
       "...            ...               ...     ...           ...\n",
       "1540          True                 1  Reject             0\n",
       "1541         False                 0  Reject             0\n",
       "1542          True                 1  Reject             0\n",
       "1543         False                 0  Reject             0\n",
       "1544          True                 1  Reject             0\n",
       "\n",
       "[1538 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ACL_df['had_rebuttal_int']=ACL_df.had_rebuttal.apply(lambda x: int(x))\n",
    "ACL_df['accepted_int']=ACL_df.status.apply(lambda x: int(x==\"Accept\"))\n",
    "display(ACL_df[['had_rebuttal','had_rebuttal_int','status','accepted_int']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "087d1a0689224816887dcd2f1546d9b4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.3** Create a function `numpy_helper(df, cols)` to obtain a numpy.array out of your dataframe. The function should receive a dataframe `df` with N rows and a list of M columns `cols`, and should return a `np.array` of dimension `(NxM)` cast as a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_id": "3873d0f6a3644d76aa7106e284a83122",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 61,
    "execution_start": 1701441891632,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "def numpy_helper(df, cols):\n",
    "    \"\"\"\n",
    "    Function to obtain a numpy array from a dataframe\n",
    "    \n",
    "    Arguments :\n",
    "        @df <pandas.DataFrame>: Input dataframe \n",
    "        @cols <list>: columns\n",
    "    \"\"\"\n",
    "    return np.array(df[cols].values, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "78122f2122614fdc979cc1c7d0736809",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.4**\n",
    "Create:\n",
    "- an array of features X containing all track one-hot features, as well as the `overall_score_before_avg`,`overall_score_before_std`, and `had_rebuttal_int`;\n",
    "- an array of outcomes y containing `accepted_int`. \n",
    "\n",
    "\n",
    "Print the shapes of both X and y (e.g., `X.shape`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "db6149fca64a4887830f63f9a4abce86",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 54,
    "execution_start": 1701441891636,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape : (1538, 24) ; y shape : (1538,).\n"
     ]
    }
   ],
   "source": [
    "# Select necessary columns from the dataframe\n",
    "X_cols = [\"overall_score_before_avg\",\"overall_score_before_std\"]\n",
    "for col in ACL_df.columns:\n",
    "    if (\"-onehot\" in col):\n",
    "        X_cols.append(col)\n",
    "X_cols.append(\"had_rebuttal_int\")\n",
    "\n",
    "X = numpy_helper(ACL_df, X_cols)\n",
    "y = numpy_helper(ACL_df, [\"accepted_int\"])[:,0]\n",
    "\n",
    "# Print the shapes of X and y\n",
    "print(f\"X shape : {X.shape} ; y shape : {y.shape}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9457731dd9d140d39a8e70e1dfbd4a7f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.5** Build two `GradientBoostingClassifier` models using `sklearn` using the default parameters:\n",
    "- Model 1: predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std`.\n",
    "- Model 2:  predicts the outcome `accepted_int` using the onehot encoded features related to track, as well as the `overall_score_before_avg`,`overall_score_before_std` **and** `had_rebuttal_int`.\n",
    "\n",
    "\n",
    "For both models:\n",
    "\n",
    "- Use the `cross_validate` function from `sklearn.model_selection` to compute the average precision, recall, and accuracy across test cross validation splits.\n",
    "\n",
    "    - e.g., `cross_validate(clf, X, y, cv=30, scoring=('accuracy', 'precision', 'recall'))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_id": "9b23cfd8ae794ede9387a60781cc53b8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6350,
    "execution_start": 1701441891644,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "#Remove the column 'had_rebuttal_int' (last one of X) and fit model 1\n",
    "classifier1 = GradientBoostingClassifier().fit(X[:,0:-1],y)\n",
    "#Fit model 2 on the whole array X\n",
    "classifier2 = GradientBoostingClassifier().fit(X,y)\n",
    "\n",
    "cv1 = cross_validate(classifier1, X[:,0:-1], y, cv=30,\n",
    "                     scoring=('accuracy', 'precision', 'recall'))\n",
    "cv2 = cross_validate(classifier2, X, y, cv=30,\n",
    "                     scoring=('accuracy', 'precision', 'recall'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b4ddf377822b458cb6f0fa25835044b4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**2.6** Determine whether the difference in accuracy of the two models is statistically significant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "cell_id": "fc38ac2fc43d4f47bd449abf43392795",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1701441897987,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value :  0.48357829299551125\n",
      "The difference in accuracy is NOT statistically significant.\n"
     ]
    }
   ],
   "source": [
    "#T-test between the two models\n",
    "t_statistic, p_value = stats.ttest_rel(cv1[\"test_accuracy\"], cv2[\"test_accuracy\"])\n",
    "alpha = 0.05  # significance level\n",
    "print(\"p-value : \", p_value)\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"The difference in accuracy is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in accuracy is NOT statistically significant.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e96b1498d17d44318db04b8e12a3dbac",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 6,
      "type": "marks"
     }
    ]
   },
   "source": [
    "**Answer:** \n",
    "\n",
    "The difference in accuracy between models donsidering \n",
    "- the `score_before_avg`, `score_after_avg` and the `-onehot` features (1) \n",
    "- or all these features plus the `had_rebuttal_int` (2)\n",
    "\n",
    "is **NOT** significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d025a0fe4ae0471cba2be31a66c3e201",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**2.7** Contrast the results obtained in **2.6** with what you observed in **Task 1**. What advantage did the analyses in **2.6** have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "83c737a95fe243e9b19d1db2034c1612",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 204,
      "marks": {
       "code": true
      },
      "toCodePoint": 205,
      "type": "marks"
     }
    ]
   },
   "source": [
    "**Answer:** In task 1, we found that the conditional probabilities of acceptation knowing whether or not there had been a rebuttal were very  different. This lead us into thinking that rebuttals help being accepted. \n",
    "However, in task 2, we trained 2 models to predict a binary outcome: whether or not a paper is accepted.\n",
    "Both models use common features (namely track and scores), but in addition, model 2 considers the binary predictor `had_rebuttal_int`, which model 1 does not. We then look at the accuracy of both models, to assess the quality of each.\n",
    "We compare the accuracies with a t-test, to understand if adding the `had_rebuttal_int` feature significantly increases the accuracy of the prediction. \n",
    "\n",
    "In 2.6 we find out a p-value of 0.484, way superior to 0.05. Therefore, **we cannot conclude that rebuttals play a significant role** in the chances of being accepted.\n",
    "\n",
    "The advantages of the analysis performed in 2.6 are the following: \n",
    "- We added predictors: the tracks and the scores. This refines the analysis (for instance, some tracks could be more accepted/represented than others, which could have twisted the results in task 1). Scores are obviously linked with acceptance.\n",
    "- Using classifiers' accuracy (with and without rebuttal feature) to better understand the role of this feature in predicting acceptance is more relevant than just looking at the observed percentages, which are only one representation of a fixed dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8cee63b5932c4169a6f6ab8240b75a50",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Task 3 (12pts): Interlude\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "6ee8de5b575a4f03b1b018e95a4ec3d8",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**3.1** Using the formula API from `statsmodels`, estimate the following linear regression. Report the summary of the models.\n",
    "- `accepted_int ~ had_rebuttal_int`,  \n",
    "- `accepted_int ~ overall_score_after_avg`\n",
    "- `had_rebuttal_int ~ overall_score_before_avg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "cell_id": "e84a0112db0e4b879d05cccb7db7b6cb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 103,
    "execution_start": 1701441897999,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Model 1 Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>accepted_int</td>   <th>  R-squared:         </th> <td>   0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   66.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>8.24e-16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:22:59</td>     <th>  Log-Likelihood:    </th> <td> -855.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1538</td>      <th>  AIC:               </th> <td>   1714.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1536</td>      <th>  BIC:               </th> <td>   1725.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    0.0838</td> <td>    0.023</td> <td>    3.693</td> <td> 0.000</td> <td>    0.039</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>had_rebuttal_int</th> <td>    0.2098</td> <td>    0.026</td> <td>    8.138</td> <td> 0.000</td> <td>    0.159</td> <td>    0.260</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.753</td> <th>  Durbin-Watson:     </th> <td>   1.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 324.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.075</td>  <th>  Prob(JB):          </th> <td>3.65e-71</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.336</td>  <th>  Cond. No.          </th> <td>    4.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &  accepted\\_int   & \\textbf{  R-squared:         } &     0.041   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.041   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &     66.22   \\\\\n",
       "\\textbf{Date:}              & Fri, 01 Dec 2023 & \\textbf{  Prob (F-statistic):} &  8.24e-16   \\\\\n",
       "\\textbf{Time:}              &     20:22:59     & \\textbf{  Log-Likelihood:    } &   -855.16   \\\\\n",
       "\\textbf{No. Observations:}  &        1538      & \\textbf{  AIC:               } &     1714.   \\\\\n",
       "\\textbf{Df Residuals:}      &        1536      & \\textbf{  BIC:               } &     1725.   \\\\\n",
       "\\textbf{Df Model:}          &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}          &       0.0838  &        0.023     &     3.693  &         0.000        &        0.039    &        0.128     \\\\\n",
       "\\textbf{had\\_rebuttal\\_int} &       0.2098  &        0.026     &     8.138  &         0.000        &        0.159    &        0.260     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.753 & \\textbf{  Durbin-Watson:     } &    1.920  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  324.377  \\\\\n",
       "\\textbf{Skew:}          &   1.075 & \\textbf{  Prob(JB):          } & 3.65e-71  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.336 & \\textbf{  Cond. No.          } &     4.00  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Model 1 Summary}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               Model 1 Summary                                \n",
       "==============================================================================\n",
       "Dep. Variable:           accepted_int   R-squared:                       0.041\n",
       "Model:                            OLS   Adj. R-squared:                  0.041\n",
       "Method:                 Least Squares   F-statistic:                     66.22\n",
       "Date:                Fri, 01 Dec 2023   Prob (F-statistic):           8.24e-16\n",
       "Time:                        20:22:59   Log-Likelihood:                -855.16\n",
       "No. Observations:                1538   AIC:                             1714.\n",
       "Df Residuals:                    1536   BIC:                             1725.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            0.0838      0.023      3.693      0.000       0.039       0.128\n",
       "had_rebuttal_int     0.2098      0.026      8.138      0.000       0.159       0.260\n",
       "==============================================================================\n",
       "Omnibus:                      271.753   Durbin-Watson:                   1.920\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              324.377\n",
       "Skew:                           1.075   Prob(JB):                     3.65e-71\n",
       "Kurtosis:                       2.336   Cond. No.                         4.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Model 2 Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>accepted_int</td>   <th>  R-squared:         </th> <td>   0.402</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.401</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1031.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.58e-173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:22:59</td>     <th>  Log-Likelihood:    </th> <td> -492.65</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1538</td>      <th>  AIC:               </th> <td>   989.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1536</td>      <th>  BIC:               </th> <td>   1000.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>               <td>   -0.6558</td> <td>    0.029</td> <td>  -22.339</td> <td> 0.000</td> <td>   -0.713</td> <td>   -0.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overall_score_after_avg</th> <td>    0.2860</td> <td>    0.009</td> <td>   32.111</td> <td> 0.000</td> <td>    0.269</td> <td>    0.303</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>110.778</td> <th>  Durbin-Watson:     </th> <td>   1.927</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  51.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.256</td>  <th>  Prob(JB):          </th> <td>5.99e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.263</td>  <th>  Cond. No.          </th> <td>    12.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &  accepted\\_int   & \\textbf{  R-squared:         } &     0.402   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.401   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     1031.   \\\\\n",
       "\\textbf{Date:}                      & Fri, 01 Dec 2023 & \\textbf{  Prob (F-statistic):} & 1.58e-173   \\\\\n",
       "\\textbf{Time:}                      &     20:22:59     & \\textbf{  Log-Likelihood:    } &   -492.65   \\\\\n",
       "\\textbf{No. Observations:}          &        1538      & \\textbf{  AIC:               } &     989.3   \\\\\n",
       "\\textbf{Df Residuals:}              &        1536      & \\textbf{  BIC:               } &     1000.   \\\\\n",
       "\\textbf{Df Model:}                  &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      -0.6558  &        0.029     &   -22.339  &         0.000        &       -0.713    &       -0.598     \\\\\n",
       "\\textbf{overall\\_score\\_after\\_avg} &       0.2860  &        0.009     &    32.111  &         0.000        &        0.269    &        0.303     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 110.778 & \\textbf{  Durbin-Watson:     } &    1.927  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   51.680  \\\\\n",
       "\\textbf{Skew:}          &   0.256 & \\textbf{  Prob(JB):          } & 5.99e-12  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.263 & \\textbf{  Cond. No.          } &     12.3  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Model 2 Summary}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               Model 2 Summary                                \n",
       "==============================================================================\n",
       "Dep. Variable:           accepted_int   R-squared:                       0.402\n",
       "Model:                            OLS   Adj. R-squared:                  0.401\n",
       "Method:                 Least Squares   F-statistic:                     1031.\n",
       "Date:                Fri, 01 Dec 2023   Prob (F-statistic):          1.58e-173\n",
       "Time:                        20:22:59   Log-Likelihood:                -492.65\n",
       "No. Observations:                1538   AIC:                             989.3\n",
       "Df Residuals:                    1536   BIC:                             1000.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "Intercept                  -0.6558      0.029    -22.339      0.000      -0.713      -0.598\n",
       "overall_score_after_avg     0.2860      0.009     32.111      0.000       0.269       0.303\n",
       "==============================================================================\n",
       "Omnibus:                      110.778   Durbin-Watson:                   1.927\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               51.680\n",
       "Skew:                           0.256   Prob(JB):                     5.99e-12\n",
       "Kurtosis:                       2.263   Cond. No.                         12.3\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Model 3 Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>had_rebuttal_int</td> <th>  R-squared:         </th> <td>   0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   240.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Dec 2023</td> <th>  Prob (F-statistic):</th> <td>1.89e-50</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:22:59</td>     <th>  Log-Likelihood:    </th> <td> -727.42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1538</td>      <th>  AIC:               </th> <td>   1459.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1536</td>      <th>  BIC:               </th> <td>   1470.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>    0.2527</td> <td>    0.035</td> <td>    7.195</td> <td> 0.000</td> <td>    0.184</td> <td>    0.322</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>overall_score_before_avg</th> <td>    0.1651</td> <td>    0.011</td> <td>   15.499</td> <td> 0.000</td> <td>    0.144</td> <td>    0.186</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>201.621</td> <th>  Durbin-Watson:     </th> <td>   1.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 288.526</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.060</td>  <th>  Prob(JB):          </th> <td>2.23e-63</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.890</td>  <th>  Cond. No.          </th> <td>    12.7</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}              & had\\_rebuttal\\_int & \\textbf{  R-squared:         } &     0.135   \\\\\n",
       "\\textbf{Model:}                      &        OLS         & \\textbf{  Adj. R-squared:    } &     0.135   \\\\\n",
       "\\textbf{Method:}                     &   Least Squares    & \\textbf{  F-statistic:       } &     240.2   \\\\\n",
       "\\textbf{Date:}                       &  Fri, 01 Dec 2023  & \\textbf{  Prob (F-statistic):} &  1.89e-50   \\\\\n",
       "\\textbf{Time:}                       &      20:22:59      & \\textbf{  Log-Likelihood:    } &   -727.42   \\\\\n",
       "\\textbf{No. Observations:}           &         1538       & \\textbf{  AIC:               } &     1459.   \\\\\n",
       "\\textbf{Df Residuals:}               &         1536       & \\textbf{  BIC:               } &     1470.   \\\\\n",
       "\\textbf{Df Model:}                   &            1       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}            &     nonrobust      & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                   &       0.2527  &        0.035     &     7.195  &         0.000        &        0.184    &        0.322     \\\\\n",
       "\\textbf{overall\\_score\\_before\\_avg} &       0.1651  &        0.011     &    15.499  &         0.000        &        0.144    &        0.186     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 201.621 & \\textbf{  Durbin-Watson:     } &    1.930  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  288.526  \\\\\n",
       "\\textbf{Skew:}          &  -1.060 & \\textbf{  Prob(JB):          } & 2.23e-63  \\\\\n",
       "\\textbf{Kurtosis:}      &   2.890 & \\textbf{  Cond. No.          } &     12.7  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Model 3 Summary}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                               Model 3 Summary                                \n",
       "==============================================================================\n",
       "Dep. Variable:       had_rebuttal_int   R-squared:                       0.135\n",
       "Model:                            OLS   Adj. R-squared:                  0.135\n",
       "Method:                 Least Squares   F-statistic:                     240.2\n",
       "Date:                Fri, 01 Dec 2023   Prob (F-statistic):           1.89e-50\n",
       "Time:                        20:22:59   Log-Likelihood:                -727.42\n",
       "No. Observations:                1538   AIC:                             1459.\n",
       "Df Residuals:                    1536   BIC:                             1470.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Intercept                    0.2527      0.035      7.195      0.000       0.184       0.322\n",
       "overall_score_before_avg     0.1651      0.011     15.499      0.000       0.144       0.186\n",
       "==============================================================================\n",
       "Omnibus:                      201.621   Durbin-Watson:                   1.930\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              288.526\n",
       "Skew:                          -1.060   Prob(JB):                     2.23e-63\n",
       "Kurtosis:                       2.890   Cond. No.                         12.7\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creation and display of the three models\n",
    "formula1 = 'accepted_int ~ had_rebuttal_int'\n",
    "formula2 = 'accepted_int ~ overall_score_after_avg'\n",
    "formula3 = 'had_rebuttal_int ~ overall_score_before_avg'\n",
    "\n",
    "model1 = smf.ols(formula=formula1, data=ACL_df).fit()\n",
    "model2 = smf.ols(formula=formula2, data=ACL_df).fit()\n",
    "model3 = smf.ols(formula=formula3, data=ACL_df).fit()\n",
    "\n",
    "display(model1.summary(title=\"Model 1 Summary\"))\n",
    "display(model2.summary(title=\"Model 2 Summary\"))\n",
    "display(model3.summary(title=\"Model 3 Summary\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1c020cf38355473c8f883029d037b1c4",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**3.2** **/Discuss:/** Interpret the coefficients associated with the binary independent variables in the above models. Note that independent variables are the ones on the right-handside of the equation.\n",
    "\n",
    "- e.g., in `had_rebuttal_int ~ overall_score_before_avg`, `overall_score_before_avg` is the independent variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e0f4972f8d034064bc119c3273248a5d",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": [
     {
      "fromCodePoint": 0,
      "marks": {
       "bold": true
      },
      "toCodePoint": 6,
      "type": "marks"
     }
    ]
   },
   "source": [
    "**Answer:** The only binary independent variable is `had_rebuttal_int`, in model 1, whose coefficients are:\n",
    "- Coefficients: slope = 0.2098 and intercept = 0.0838\n",
    "- P-value: < 0.001\n",
    "\n",
    "In Model 1, the coefficient associated with `had_rebuttal_int` is 0.2098. This means that, on average, papers with a rebuttal have a 0.2098 increase in the log-odds of being accepted compared to papers without a rebuttal. The p-value of < 0.001 indicates that this coefficient is statistically significant, suggesting that the presence of a rebuttal has a significant impact on the acceptance of papers. \n",
    "\n",
    "We can notice that these coefficients correspond to the percentages we had computed in question 1.3: \n",
    "- The intercept (0.0838) is the percentage of papers that were accepted without rebuttal (`had_rebuttal_int` = 0)\n",
    "- The slope (0.2098) is the average acceptance difference between papers with and without rebuttals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bbc9975e612b46299876fc9f5cf91366",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**3.3** **/Discuss:/** describe three correlations you can draw from the previous analysis. Describe their sign (i.e., whether they are positive or negative), and whether they are statistically significant (at the .05 level of significance).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a70267c0058f4e0b8d9f3e7b176972e6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "\n",
    "\n",
    "1. Correlation between `accepted_int` and `had_rebuttal_int`:\n",
    "   - Sign: Positive\n",
    "   - Statistical Significance: Yes (p-value < 0.001)\n",
    "   \n",
    "Therefore, **papers with a rebuttal are more likely to be accepted**.\n",
    "\n",
    "\n",
    "2. Correlation between `accepted_int` and `overall_score_after_avg`:\n",
    "   - Sign: Positive\n",
    "   - Statistical Significance: Yes (p-value < 0.001)\n",
    "   \n",
    "Therefore, **papers with a high overall score after average are more likely to be accepted**.\n",
    "   \n",
    "3. Correlation between `had_rebuttal_int` and `overall_score_before_avg`:\n",
    "   - Sign: Positive\n",
    "   - Statistical Significance: Yes (p-value < 0.001)\n",
    "   \n",
    "Therefore, **papers with a rebuttal are more likely to have a high overall score before average**.\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e5097a209f734802aee5fff6e2723845",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**3.4** **/Discuss:/** Is the following statement True or False? Justify. \n",
    "\n",
    "- The variable `overall_score_after_avg` explains more of the variance in `accepted_int`than the variable `overall_score_before_avg` explains of `had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "859f317a8e004da6b1d4fce0127ec00f",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "**Answer:** True.\n",
    "\n",
    "We look at the adjusted R squared coefficients of models 2 and 3 : $R_{model2}^2 = 0.401$ and $R_{model3}^2 = 0.135$.\n",
    "\n",
    "Since the R squared coefficient assesses the predictor's ability to explain the variance of the response variable, we conclude that `overall_score_after_avg` explains more of the variance in `accepted_int` than `overall_score_before_avg` explains of `had_rebuttal_int`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0c331333521b4fa7b9b3b3b16b7d2363",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**3.5** **/Discuss:/** Create a causal diagram relating the following variables:\n",
    "- \"Sa\": `overall_score_after_avg`\n",
    "- \"Sb\": `overall_score_before_avg`\n",
    "- \"Re\": `had_rebuttal_int`\n",
    "- \"Ac\": `accepted_int`\n",
    "- \"Tr\": `track`\n",
    "\n",
    "\n",
    "When unsure about whether a causal relationship exists, include it in the diagram. E.g., include the arrow corresponding to the key questions around this homework, i.e., `had_rebuttal_int`->`accepted_int`, even though you are investigating whether it exists. \n",
    "\n",
    "You may draw your diagram using text, use Sa/Sb/Re/Ac/Tr to represent the names of the variables, and simply indicate the causal links, one per line.\n",
    "\n",
    "\n",
    "Instead of drawing something like this:\n",
    "![](./dagv.jpeg)\n",
    "\n",
    "Simply write:\n",
    "\n",
    "- Tr->Sb\n",
    "- Tr->Ac\n",
    "- Tr->Re\n",
    "- Ac->Sb\n",
    "- Re->Sb\n",
    "- Sb->Sa\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d8f5ff48f179469e955b2a86e658aa1d",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**Answer:** Track can have bias (the same group of authors, that have always the same method) and influence every trait.\n",
    "- Tr->Sb (The track can have a bias towards certain types of submissions)\n",
    "- Tr->Sa (The track can influence the acceptance of submissions based on its specific criteria and preferences)\n",
    "- Tr->Re (The track can influence the selection of reviewers who are experts in the specific area covered by the track)\n",
    "- Tr->Ac (The track can influence the final decision on whether a submission should be accepted or rejected)\n",
    "- Sb->Sa (A submission bias can lead to a perpetuation of certain types of papers being accepted or rejected consistently)\n",
    "- Sb->Re (If authors know they have a bad score due to submission bias, they may try to provide additional explanations or justifications for their paper to the reviewers)\n",
    "- Sb->Ac (Submission bias can indirectly influence the acceptance decision by affecting the pool of papers available for consideration)\n",
    "- Re->Sa (Reviewers can provide feedback and suggestions that can potentially improve the quality and acceptance chances of a submission)\n",
    "- Re->Ac (Reviewers' evaluations and recommendations can indirectly influence the final acceptance decision made by the program committee)\n",
    "- Sa->Ac (The acceptance decision is influenced by the quality and suitability of the submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1677eaceaab44909b4d47bdfaeb4ed4c",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**3.6** **/Discuss:/** What is the problem of simply comparing the outcomes of papers that had rebuttals with those that did not? Give a concrete example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bfea19ef373f4ea8910f8de9924c219a",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "**Answer:**  The problem is that it does not take into account the effect of confounders. Indeed, we have proven in question 3.2 that there was a positive correlation between having rebuttals and being accepted. This may mislead us into thinking that having rebuttals effectively increases chances of being accepted.\n",
    "\n",
    "However, the other two analyses prove that positive correlations exist between: \n",
    "- having a good overall score before and having rebuttals (i)\n",
    "- and having a good overall score after and being accepted (ii).\n",
    "\n",
    "There might be a confounder that affects both the average scores between and after eventual rebuttals, and that effectivly accounts for the correlation being accepted ~ have a rebuttal. This could also be the consequence of the impact of `score_before_avg` on `score_after_avg`. The correlation would just be a consequence of another causality, due to one feature.\n",
    "\n",
    "Another problem is that the papers on which we study the influence of rebuttals don't have the same initial features. So maybe papers with rebuttals are usually done by conscientious scholars who get good scores at the beginning, and would have passed even without rebuttals, whereas papers without rebuttals are done by non-experts who get terrible scores at the beginning and wouldn't even pass despite rebuttals. The track may also be important: for example, in a selective field, there could be less papers proposed and thus a higher acceptance ratio, that would not be due to rebuttals. **Therefore the optimal thing to do is to compare papers that have similar initial features** (track, score_before, ...) and see whether having a rebuttal really helps them be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d8c8f2e55e7f41a98380783c02cda8f6",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Task 4 (12 pts): Observational study\n",
    "\n",
    "You decide to use your observational study skills to obtain a concrete answer to the question: do rebuttals increase acceptance?\n",
    "\n",
    " **4.1** Perform exact one-to-one matching considering the `score_before_avg` and the `track` variables. Each paper that had a rebuttal (\"treatment group\") should be matched to a paper that did not have a rebuttal (\"control group\"). \n",
    "- Your matching should be optimal, i.e., the maximum amount of papers possible must be matched. \n",
    "- Print the dataframe of papers in the matched sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "cell_id": "1893a65f6e8242a6b754166375459ce2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 605,
    "execution_start": 1701442519155,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmp_id</th>\n",
       "      <th>status</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>track</th>\n",
       "      <th>had_rebuttal</th>\n",
       "      <th>overall_score_before_avg</th>\n",
       "      <th>overall_score_before_std</th>\n",
       "      <th>overall_score_after_avg</th>\n",
       "      <th>overall_score_after_std</th>\n",
       "      <th>had_rebuttal_int</th>\n",
       "      <th>accepted_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P193</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P727</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P991</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>False</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P4</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>True</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>P1157</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>False</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>P644</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>P1004</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>False</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>P1234</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Short</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>True</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.247219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>P1004</td>\n",
       "      <td>Reject</td>\n",
       "      <td>Long</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>False</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.471405</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1360 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tmp_id  status submission_type             track  had_rebuttal  \\\n",
       "0        P1  Reject            Long  Machine Learning          True   \n",
       "1      P193  Reject            Long  Machine Learning         False   \n",
       "2      P727  Reject            Long  Machine Learning          True   \n",
       "3      P991  Reject           Short  Machine Learning         False   \n",
       "4        P4  Reject           Short  Machine Learning          True   \n",
       "...     ...     ...             ...               ...           ...   \n",
       "1355  P1157  Reject           Short      Social Media         False   \n",
       "1356   P644  Reject            Long      Social Media          True   \n",
       "1357  P1004  Reject            Long      Social Media         False   \n",
       "1358  P1234  Reject           Short      Social Media          True   \n",
       "1359  P1004  Reject            Long      Social Media         False   \n",
       "\n",
       "      overall_score_before_avg  overall_score_before_std  \\\n",
       "0                     2.500000                  0.500000   \n",
       "1                     2.500000                  0.500000   \n",
       "2                     2.500000                  0.500000   \n",
       "3                     2.500000                  1.500000   \n",
       "4                     3.000000                  0.816497   \n",
       "...                        ...                       ...   \n",
       "1355                  1.500000                  0.500000   \n",
       "1356                  2.666667                  0.471405   \n",
       "1357                  2.666667                  0.471405   \n",
       "1358                  2.666667                  1.247219   \n",
       "1359                  2.666667                  0.471405   \n",
       "\n",
       "      overall_score_after_avg  overall_score_after_std  had_rebuttal_int  \\\n",
       "0                    2.500000                 0.500000                 1   \n",
       "1                    2.500000                 0.500000                 0   \n",
       "2                    2.333333                 0.471405                 1   \n",
       "3                    2.666667                 0.471405                 0   \n",
       "4                    2.666667                 1.247219                 1   \n",
       "...                       ...                      ...               ...   \n",
       "1355                 1.500000                 0.500000                 0   \n",
       "1356                 2.666667                 0.471405                 1   \n",
       "1357                 2.666667                 0.471405                 0   \n",
       "1358                 2.666667                 1.247219                 1   \n",
       "1359                 2.666667                 0.471405                 0   \n",
       "\n",
       "      accepted_int  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "1355             0  \n",
       "1356             0  \n",
       "1357             0  \n",
       "1358             0  \n",
       "1359             0  \n",
       "\n",
       "[1360 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#EXACT matching \n",
    "treatment_group = ACL_df[ACL_df['had_rebuttal_int']==1]\n",
    "control_group = ACL_df[ACL_df['had_rebuttal_int']==0]\n",
    "matched_samples = []\n",
    "column_names_ACL = ACL_df[['tmp_id', 'status', 'submission_type',\n",
    "            'track', 'had_rebuttal', 'overall_score_before_avg', \n",
    "            'overall_score_before_std', 'overall_score_after_avg', \n",
    "            'overall_score_after_std','had_rebuttal_int','accepted_int']].columns\n",
    "\n",
    "#List of unique tracks \n",
    "Track_list = treatment_group['track'].unique()\n",
    "\n",
    "#Loop on unique tracks \n",
    "for track in Track_list : \n",
    "    #List of the unique grades in the paper having the required track \n",
    "    grade_list = treatment_group[\n",
    "        treatment_group['track']==track]['overall_score_before_avg'].unique()\n",
    "    #Loop on unique grades\n",
    "    for grade in grade_list : \n",
    "        #This is exectued for all the unique pairs (track,overall_score_avg)\n",
    "        #We find the matching paper in both groups \n",
    "        pair_control = control_group[(control_group['track']== track)\n",
    "                            & (control_group['overall_score_before_avg'] == grade)]\n",
    "        pair_treatment = treatment_group[(treatment_group['track']== track)\n",
    "                            & (treatment_group['overall_score_before_avg'] == grade)]\n",
    "        \n",
    "        nb_match = len(pair_control)\n",
    "        if nb_match == 0 : \n",
    "            #No matching paper have been found in the control group\n",
    "            continue \n",
    "        else : \n",
    "            #Addition of the two matched papers to the matched sample dataset \n",
    "            k = 0 \n",
    "            for _,paper in pair_treatment.iterrows() : \n",
    "                pair = pair_control.iloc[k%nb_match]\n",
    "                matched_samples.append([paper[col] for col in column_names_ACL])\n",
    "                matched_samples.append([pair[col] for col in column_names_ACL])\n",
    "                k+=1\n",
    "    \n",
    "\n",
    "matched_df = pd.DataFrame(matched_samples,columns = column_names_ACL)\n",
    "display(matched_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "ff41cb44727e436993af184df9a920de",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**4.2** So far, we did not consider the `score_before_std` variable. One could argue that the variance in the scores makes a difference. E.g., a paper that received scores 1 and 5, might be very different from a paper with scores 3 and 3. \n",
    "\n",
    "Note that you did not match on the `score_before_std` variable. However, it suffices if this variable is \"balanced\" across treatment and control groups.\n",
    " Use the Standardized Mean Difference (SMD) to assess whether that's the case.\n",
    "\n",
    "- The standardized mean difference for a variable $x$ and two groups $t$ and $c$ is defined as: $\\frac{| E[x_t] - E[x_c] |}{\\sqrt{Var[x_t] + Var[x_c]}}$\n",
    "\n",
    "- Note that a Standardized Mean Difference smaller than 0.1 suggests that variables are balanced across treatment and control groups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "cell_id": "789a8aa872c04931b7c7b921642d8aae",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 13,
    "execution_start": 1701442394445,
    "source_hash": null
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMD: 0.09462551768993871\n",
      "The score_before_std variable is balanced across treatment and control groups.\n"
     ]
    }
   ],
   "source": [
    "mean_treatment= matched_df.query('had_rebuttal_int == 1').overall_score_before_std.mean()\n",
    "mean_control  = matched_df.query('had_rebuttal_int == 0').overall_score_before_std.mean()\n",
    "var_treatment = matched_df.query('had_rebuttal_int == 1').overall_score_before_std.var()\n",
    "var_control   = matched_df.query('had_rebuttal_int == 0').overall_score_before_std.var()\n",
    "\n",
    "# Calculus of the Standardized Mean Difference (SMD)\n",
    "smd = abs(mean_treatment - mean_control) / np.sqrt(var_treatment + var_control)\n",
    "\n",
    "# Check the given condition on the SMD\n",
    "print(\"SMD:\", smd)\n",
    "if smd < 0.1:\n",
    "    print(\"The score_before_std variable is balanced \"+\n",
    "          \"across treatment and control groups.\")\n",
    "else:\n",
    "    print(\"The score_before_std variable is NOT balanced \"+\n",
    "          \"across treatment and control groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7cbc936f41a844c69af1e313cb8dae21",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**4.3** Using the matched sample, estimate the following linear regression: `accepted ~ had_rebuttal_int`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "cell_id": "1eadd31d4709433498143a8a6877b7a8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 47,
    "execution_start": 1701442441098,
    "source_hash": null
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>      <td>accepted_int</td>   <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.04719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 01 Dec 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.828</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:26:20</td>     <th>  Log-Likelihood:    </th> <td> -592.92</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1360</td>      <th>  AIC:               </th> <td>   1190.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1358</td>      <th>  BIC:               </th> <td>   1200.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>        <td>    0.1662</td> <td>    0.014</td> <td>   11.572</td> <td> 0.000</td> <td>    0.138</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>had_rebuttal_int</th> <td>    0.0044</td> <td>    0.020</td> <td>    0.217</td> <td> 0.828</td> <td>   -0.035</td> <td>    0.044</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>387.507</td> <th>  Durbin-Watson:     </th> <td>   1.397</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 785.770</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.772</td>  <th>  Prob(JB):          </th> <td>2.36e-171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.141</td>  <th>  Cond. No.          </th> <td>    2.62</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}     &  accepted\\_int   & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Model:}             &       OLS        & \\textbf{  Adj. R-squared:    } &    -0.001   \\\\\n",
       "\\textbf{Method:}            &  Least Squares   & \\textbf{  F-statistic:       } &   0.04719   \\\\\n",
       "\\textbf{Date:}              & Fri, 01 Dec 2023 & \\textbf{  Prob (F-statistic):} &    0.828    \\\\\n",
       "\\textbf{Time:}              &     21:26:20     & \\textbf{  Log-Likelihood:    } &   -592.92   \\\\\n",
       "\\textbf{No. Observations:}  &        1360      & \\textbf{  AIC:               } &     1190.   \\\\\n",
       "\\textbf{Df Residuals:}      &        1358      & \\textbf{  BIC:               } &     1200.   \\\\\n",
       "\\textbf{Df Model:}          &           1      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}          &       0.1662  &        0.014     &    11.572  &         0.000        &        0.138    &        0.194     \\\\\n",
       "\\textbf{had\\_rebuttal\\_int} &       0.0044  &        0.020     &     0.217  &         0.828        &       -0.035    &        0.044     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 387.507 & \\textbf{  Durbin-Watson:     } &     1.397  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   785.770  \\\\\n",
       "\\textbf{Skew:}          &   1.772 & \\textbf{  Prob(JB):          } & 2.36e-171  \\\\\n",
       "\\textbf{Kurtosis:}      &   4.141 & \\textbf{  Cond. No.          } &      2.62  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:           accepted_int   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.001\n",
       "Method:                 Least Squares   F-statistic:                   0.04719\n",
       "Date:                Fri, 01 Dec 2023   Prob (F-statistic):              0.828\n",
       "Time:                        21:26:20   Log-Likelihood:                -592.92\n",
       "No. Observations:                1360   AIC:                             1190.\n",
       "Df Residuals:                    1358   BIC:                             1200.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================\n",
       "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Intercept            0.1662      0.014     11.572      0.000       0.138       0.194\n",
       "had_rebuttal_int     0.0044      0.020      0.217      0.828      -0.035       0.044\n",
       "==============================================================================\n",
       "Omnibus:                      387.507   Durbin-Watson:                   1.397\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              785.770\n",
       "Skew:                           1.772   Prob(JB):                    2.36e-171\n",
       "Kurtosis:                       4.141   Cond. No.                         2.62\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear regression 'accepted_int ~ had_rebuttal_int' gives:\n",
      "intercep = 0.1662\n",
      "slope = 0.0044\n"
     ]
    }
   ],
   "source": [
    "final_model = smf.ols(formula = 'accepted_int ~ had_rebuttal_int',\n",
    "                      data = matched_df).fit()\n",
    "\n",
    "display(final_model.summary())\n",
    "\n",
    "print(\"The linear regression 'accepted_int ~ had_rebuttal_int' gives:\")\n",
    "print(f'intercep = {(np.round(final_model.params[0], 4))}') \n",
    "print(f'slope = {(np.round(final_model.params[1], 4))}')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9f058cbc6efd4c52ac5b022f9d8ca56f",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "\n",
    "**4.4** **/Discuss:/**\n",
    "\n",
    "i. Considering your results obtained in 4.3, and the causal diagram drawn in Task 3: do rebuttals increase the chance of a paper getting accepted? Why are results different from what you obtained in **Task 1?**\n",
    "\n",
    "ii. Why is there no need to include other covariates (e.g., score before) in the regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "554488ee7da94e889e8d5dee14d6ed9e",
    "deepnote_cell_type": "markdown",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 7,
    "execution_start": 1701381109050,
    "source_hash": "f2c6abb5"
   },
   "source": [
    "**Answer i :**\n",
    "The linear regression gives a slope of $0.0044$, so rebuttals seem to slightly increase the chances of being accepted. However, the p-value is so high (0.828) that we cannot conclude on the real impact of rebuttals on acceptance.\n",
    "\n",
    "Results are different from what we had in Task 1 (where we had concluded that rebuttals helped being accepted) since now, we reduce the sample to only matched pairs by creating a control group and a treatment group (without and with rebuttals). This way, we only compare papers which have similar traits, which reduces the impact of predictors presented in Task 3. As regards the matching, we have matched papers only based on two criteria: the track and the overall score before, because only these two are not influenced (see graph in 3.5) by the possible presence of rebuttal.\n",
    "\n",
    "Conversely, in Task 1, we naïvely compared all the papers, neither by taking any confounder into account, nor by clustering the papers into relevant and comparable subgroups. Therefore, we saw an illusional pattern when considering the whole group of papers, pattern that fades out when we consider relevant subgroups.\n",
    "\n",
    "**Answer ii :** First, it is obviously irrelevant to use the covariates used to do the clustering. \n",
    "Indeed, by doing the matching, we created pairs that have the same track and score before. Therefore, these two parametes have their effect neutralised in the linear regression. It is useless to include them as covariates.\n",
    "Also, we have checked that the standard deviation of scores before is balanced between treatment and control groups.\n",
    "\n",
    "Remains the possibility of including the average score after as a covariate.\n",
    "Such a linear regression would give: $Acceptance = \\beta_0 + \\beta_1*hadRebuttalInt + \\beta_2*avgScoreAfter $.\n",
    "`Avg_score_after` can be highly influenced by both score before and had_rebuttal. Therefore, it is either redundant to include it as a covariate, or even detrimental. Indeed, it could weaken the $\\beta_1$ associated with `had_rebuttal` in the linear regression. If `had_rebuttal` has a great impact on `score_after_avg`, and `score_after_avg` has a great impact on `accepted_int`, we will observe a high correlation (great $\\beta_2$) related to `score_after_avg`, and a small $\\beta$ related to `had_rebuttal`, whereas in this case, the real causal link between rebuttal and acceptance could be attenuated by the apparently strong link between score_after and acceptance.)\n",
    "\n",
    "Therefore, we do not need to include any other covariate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e5e35d4653441ac8313e422f4f687d5",
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "**4.5** **/Discuss:/** Imagine there is another, unobserved variable \"quality\" which captures the true quality of the paper. Suppose quality (\"Qu\") is connected to the DAG you drew in the following ways:\n",
    "- Qu -> Sa\n",
    "- Qu -> Sb\n",
    "- Qu -> Re\n",
    "- Qu -> Ac\n",
    "Assume that\n",
    "- quality can only increase the chances of rebuttals;\n",
    "- quality and the rebuttal can only increase the chance of a paper being accepted.\n",
    "Does this uncontrolled confounder threaten the validity of your findings?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "50b0f22bce884f8386d0904ed9d2176e",
    "deepnote_cell_type": "text-cell-bullet",
    "formattedRanges": []
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "This uncontrolled confounder threatens the **method** we use in this study.\n",
    "\n",
    "- First, it will induces a bias in the composition of our treatment and control groups : since quality increases the chance of having a rebuttal, it also increases the chances of being in our treatment group. We should hence have more qualitative papers in the latter than in our control group. \n",
    "- And then, quality associated with rebuttal also increase the chance of being accepted : hence the treatment group should artificially have more accepted papers, not due to their rebuttals, but to quality.\n",
    "\n",
    "The combination of those two influences, one that makes a discrimination between our two groups and one that boost acceptance in the treatment group due to quality and not only to rebuttals, can deeply change the results of our study.\n",
    "\n",
    "However, when it comes to the findings, we concluded that rebuttals do not help significantly a paper to be accepted. Since the bias introduced by quality should lead to an artificial increase in acceptance for papers with rebuttals, conducting the same study but taking also into account quality should lead to the same conclusion. \n",
    "\n",
    "Hence this uncontrolled covariate does not threaten our final conclusion, which is that rebuttals do not help significantly your paper to be accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "cb48fe059e934a84bf265d2d0b41bab5",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
